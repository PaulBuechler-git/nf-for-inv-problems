{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from file_utils import create_versioned_dir, get_version_dir\n",
    "from flow_models import FlowModel\n",
    "from flow_models.PatchFlowModel import PatchFlowModel\n",
    "from img_utils import ImageLoader, PatchExtractor\n",
    "from transforms import image_dequantization, image_normalization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:14:12.828669Z",
     "end_time": "2023-10-19T00:14:12.866189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:14:13.423958Z",
     "end_time": "2023-10-19T00:14:13.429175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:18:02.657254Z",
     "end_time": "2023-10-19T00:18:02.701032Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_flow_trainer(name: str, path: str, model: FlowModel, loss_fn, train_images: ImageLoader, validation_images: ImageLoader,\n",
    "                       patch_size=6, batch_size=64, steps=750000, val_each_steps=1000, loss_log_each_step=100, device='cpu',\n",
    "                       quiet=False, lr=0.005):\n",
    "    if not quiet:\n",
    "        print(f'Started training for model {name}. \\n Will train {steps} steps in device={device}')\n",
    "    dir = create_versioned_dir(path, name)\n",
    "    if not quiet:\n",
    "        print(f'The weights, loss and the parameters will be stored at this location: {dir}')\n",
    "    hparams = model.get_hparams()\n",
    "    hparams['patch_size'] = patch_size\n",
    "    hparams['batch_size'] = patch_size\n",
    "    hparams['device'] = device\n",
    "    hparams['train_img_path'] = train_images.path\n",
    "    hparams['validation_img_path'] = validation_images.path\n",
    "    hparams['model_name'] = name\n",
    "    hparams['lr'] = lr\n",
    "    json.dump(hparams, open(os.path.join(dir, 'hparams.yaml'), 'w'))\n",
    "\n",
    "\n",
    "    # create sqllite3 conection to save the loss values\n",
    "    connection = sqlite3.connect(os.path.join(dir, 'loss.db'))\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"CREATE TABLE flow_model_train_loss(step, loss)\")\n",
    "    cursor.execute(\"CREATE TABLE flow_model_validation_loss(step, loss)\")\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    patch_extractor = PatchExtractor(p_size=patch_size, device=device)\n",
    "    progress_bar = tqdm(range(steps)) if not quiet else range(steps)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f'Optimizer is initialized with this parameters: {optimizer.state_dict()}')\n",
    "\n",
    "    tmp_validation_loss = 0\n",
    "    tmp_loss =0\n",
    "\n",
    "    loss_buffer = []\n",
    "\n",
    "    for step in progress_bar:\n",
    "        train_image = train_images.get_random_image()\n",
    "        train_patch_batch = patch_extractor.extract(train_image, batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        z, z_log_det = model(train_patch_batch, rev=True)\n",
    "        loss += loss_fn(z, z_log_det)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % loss_log_each_step == 0:\n",
    "            tmp_loss = loss.item()\n",
    "            if not quiet:\n",
    "                progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "            loss_buffer.append((step, loss.item()))\n",
    "\n",
    "        if step % val_each_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                val_image = validation_images.get_random_image()\n",
    "                val_patch_batch = patch_extractor.extract(val_image, batch_size)\n",
    "                z_val, z_val_log_det = model(val_patch_batch, rev=True)\n",
    "                val_loss = loss_fn(z_val, z_val_log_det)\n",
    "                tmp_validation_loss = val_loss.item()\n",
    "                # write train loss buffer and validation loss to db\n",
    "                cursor.execute(\"INSERT INTO flow_model_validation_loss VALUES(?, ?)\", (step, val_loss.item()))\n",
    "                cursor.executemany(\"INSERT INTO flow_model_train_loss VALUES(?, ?)\", loss_buffer)\n",
    "                connection.commit()\n",
    "                # save checkpoint\n",
    "                torch.save(optimizer.state_dict(), os.path.join(dir, f'optimizer_dict.pth'))\n",
    "                torch.save(model.get_state(), os.path.join(dir, f'{name}_intermediate.pth'))\n",
    "                if not quiet:\n",
    "                    progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "    connection.close()\n",
    "    torch.save(model.get_state(), os.path.join(dir, f'{name}_final.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "patch_size = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:18:03.678677Z",
     "end_time": "2023-10-19T00:18:03.699488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def log_likelihood_loss(z, z_log_det):\n",
    "    return torch.mean(0.5 * torch.sum(z**2, dim=1) - z_log_det)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:18:04.376623Z",
     "end_time": "2023-10-19T00:18:04.394909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model = PatchFlowModel(hparams={\"num_layers\": 5, \"sub_net_size\": 512, \"dimension\": patch_size ** 2}) #create_NF(num_layers=10, sub_net_size=512, dimension=patch_size**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:11:49.391436Z",
     "end_time": "2023-10-19T00:11:49.428464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "deq_normalization = T.Compose([\n",
    "    image_dequantization(device=DEVICE),\n",
    "    image_normalization()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:08:01.583523Z",
     "end_time": "2023-10-19T00:08:01.583822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_images = ImageLoader('data/material_pt_nr/train.png', transform=deq_normalization, device=DEVICE)\n",
    "validation_images = ImageLoader('data/material_pt_nr/validate.png', transform=deq_normalization, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:08:01.817950Z",
     "end_time": "2023-10-19T00:08:01.919843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for model custom_patch_nr. \n",
      " Will train 3000 steps in device=cuda\n",
      "The weights, loss and the parameters will be stored at this location: results/patch_nr/custom_patch_nr/version_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 8.30406379699707, V:8835.1484375:   0%|          | 4/3000 [00:00<01:22, 36.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer is initialized with this parameters: {'state': {}, 'param_groups': [{'lr': 0.005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: -218.11044311523438, V:-231.1395721435547: 100%|██████████| 3000/3000 [00:46<00:00, 64.58it/s] \n"
     ]
    }
   ],
   "source": [
    "patch_flow_trainer('custom_patch_nr', 'results/patch_nr', model, log_likelihood_loss, train_images, validation_images, steps=3000, patch_size=patch_size, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:11:54.810079Z",
     "end_time": "2023-10-19T00:12:41.355066Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ReversibleGraphNet:\n\tMissing key(s) in state_dict: \"module_list.10.subnet1.0.weight\", \"module_list.10.subnet1.0.bias\", \"module_list.10.subnet1.2.weight\", \"module_list.10.subnet1.2.bias\", \"module_list.10.subnet1.4.weight\", \"module_list.10.subnet1.4.bias\", \"module_list.10.subnet2.0.weight\", \"module_list.10.subnet2.0.bias\", \"module_list.10.subnet2.2.weight\", \"module_list.10.subnet2.2.bias\", \"module_list.10.subnet2.4.weight\", \"module_list.10.subnet2.4.bias\", \"module_list.11.perm\", \"module_list.11.perm_inv\", \"module_list.12.subnet1.0.weight\", \"module_list.12.subnet1.0.bias\", \"module_list.12.subnet1.2.weight\", \"module_list.12.subnet1.2.bias\", \"module_list.12.subnet1.4.weight\", \"module_list.12.subnet1.4.bias\", \"module_list.12.subnet2.0.weight\", \"module_list.12.subnet2.0.bias\", \"module_list.12.subnet2.2.weight\", \"module_list.12.subnet2.2.bias\", \"module_list.12.subnet2.4.weight\", \"module_list.12.subnet2.4.bias\", \"module_list.13.perm\", \"module_list.13.perm_inv\", \"module_list.14.subnet1.0.weight\", \"module_list.14.subnet1.0.bias\", \"module_list.14.subnet1.2.weight\", \"module_list.14.subnet1.2.bias\", \"module_list.14.subnet1.4.weight\", \"module_list.14.subnet1.4.bias\", \"module_list.14.subnet2.0.weight\", \"module_list.14.subnet2.0.bias\", \"module_list.14.subnet2.2.weight\", \"module_list.14.subnet2.2.bias\", \"module_list.14.subnet2.4.weight\", \"module_list.14.subnet2.4.bias\", \"module_list.15.perm\", \"module_list.15.perm_inv\", \"module_list.16.subnet1.0.weight\", \"module_list.16.subnet1.0.bias\", \"module_list.16.subnet1.2.weight\", \"module_list.16.subnet1.2.bias\", \"module_list.16.subnet1.4.weight\", \"module_list.16.subnet1.4.bias\", \"module_list.16.subnet2.0.weight\", \"module_list.16.subnet2.0.bias\", \"module_list.16.subnet2.2.weight\", \"module_list.16.subnet2.2.bias\", \"module_list.16.subnet2.4.weight\", \"module_list.16.subnet2.4.bias\", \"module_list.17.perm\", \"module_list.17.perm_inv\", \"module_list.18.subnet1.0.weight\", \"module_list.18.subnet1.0.bias\", \"module_list.18.subnet1.2.weight\", \"module_list.18.subnet1.2.bias\", \"module_list.18.subnet1.4.weight\", \"module_list.18.subnet1.4.bias\", \"module_list.18.subnet2.0.weight\", \"module_list.18.subnet2.0.bias\", \"module_list.18.subnet2.2.weight\", \"module_list.18.subnet2.2.bias\", \"module_list.18.subnet2.4.weight\", \"module_list.18.subnet2.4.bias\", \"module_list.19.perm\", \"module_list.19.perm_inv\". \n\tsize mismatch for module_list.0.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.0.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.0.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.0.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.0.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.0.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.2.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.2.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.2.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.2.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.2.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.2.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.4.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.4.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.4.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.4.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.4.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.4.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.6.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.6.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.6.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.6.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.6.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.6.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.8.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.8.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.8.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.8.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.8.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.8.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m version_folder \u001B[38;5;241m=\u001B[39m get_version_dir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults/patch_nr\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_patch_nr\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m \u001B[43mPatchFlowModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mversion_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom_patch_nr_intermediate.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nf-for-inv-problems/flow_models/PatchFlowModel.py:10\u001B[0m, in \u001B[0;36mPatchFlowModel.__init__\u001B[0;34m(self, hparams, path, device)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, hparams\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_layers\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msub_net_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1024\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdimension\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m7\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m}, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nf-for-inv-problems/flow_models/FlowModel.py:19\u001B[0m, in \u001B[0;36mFlowModel.__init__\u001B[0;34m(self, hparams, path, device)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo hyperparameters for model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     18\u001B[0m     created_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams)\n\u001B[0;32m---> 19\u001B[0m     \u001B[43mcreated_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnet_state_dict\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m created_model\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   2036\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2037\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2038\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[1;32m   2040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2041\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2042\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[1;32m   2043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for ReversibleGraphNet:\n\tMissing key(s) in state_dict: \"module_list.10.subnet1.0.weight\", \"module_list.10.subnet1.0.bias\", \"module_list.10.subnet1.2.weight\", \"module_list.10.subnet1.2.bias\", \"module_list.10.subnet1.4.weight\", \"module_list.10.subnet1.4.bias\", \"module_list.10.subnet2.0.weight\", \"module_list.10.subnet2.0.bias\", \"module_list.10.subnet2.2.weight\", \"module_list.10.subnet2.2.bias\", \"module_list.10.subnet2.4.weight\", \"module_list.10.subnet2.4.bias\", \"module_list.11.perm\", \"module_list.11.perm_inv\", \"module_list.12.subnet1.0.weight\", \"module_list.12.subnet1.0.bias\", \"module_list.12.subnet1.2.weight\", \"module_list.12.subnet1.2.bias\", \"module_list.12.subnet1.4.weight\", \"module_list.12.subnet1.4.bias\", \"module_list.12.subnet2.0.weight\", \"module_list.12.subnet2.0.bias\", \"module_list.12.subnet2.2.weight\", \"module_list.12.subnet2.2.bias\", \"module_list.12.subnet2.4.weight\", \"module_list.12.subnet2.4.bias\", \"module_list.13.perm\", \"module_list.13.perm_inv\", \"module_list.14.subnet1.0.weight\", \"module_list.14.subnet1.0.bias\", \"module_list.14.subnet1.2.weight\", \"module_list.14.subnet1.2.bias\", \"module_list.14.subnet1.4.weight\", \"module_list.14.subnet1.4.bias\", \"module_list.14.subnet2.0.weight\", \"module_list.14.subnet2.0.bias\", \"module_list.14.subnet2.2.weight\", \"module_list.14.subnet2.2.bias\", \"module_list.14.subnet2.4.weight\", \"module_list.14.subnet2.4.bias\", \"module_list.15.perm\", \"module_list.15.perm_inv\", \"module_list.16.subnet1.0.weight\", \"module_list.16.subnet1.0.bias\", \"module_list.16.subnet1.2.weight\", \"module_list.16.subnet1.2.bias\", \"module_list.16.subnet1.4.weight\", \"module_list.16.subnet1.4.bias\", \"module_list.16.subnet2.0.weight\", \"module_list.16.subnet2.0.bias\", \"module_list.16.subnet2.2.weight\", \"module_list.16.subnet2.2.bias\", \"module_list.16.subnet2.4.weight\", \"module_list.16.subnet2.4.bias\", \"module_list.17.perm\", \"module_list.17.perm_inv\", \"module_list.18.subnet1.0.weight\", \"module_list.18.subnet1.0.bias\", \"module_list.18.subnet1.2.weight\", \"module_list.18.subnet1.2.bias\", \"module_list.18.subnet1.4.weight\", \"module_list.18.subnet1.4.bias\", \"module_list.18.subnet2.0.weight\", \"module_list.18.subnet2.0.bias\", \"module_list.18.subnet2.2.weight\", \"module_list.18.subnet2.2.bias\", \"module_list.18.subnet2.4.weight\", \"module_list.18.subnet2.4.bias\", \"module_list.19.perm\", \"module_list.19.perm_inv\". \n\tsize mismatch for module_list.0.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.0.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.0.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.0.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.0.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.0.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.2.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.2.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.2.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.2.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.2.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.2.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.2.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.4.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.4.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.4.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.4.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.4.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.4.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.4.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.6.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.6.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.6.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.6.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.6.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.6.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.6.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024]).\n\tsize mismatch for module_list.8.subnet1.0.weight: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([1024, 24]).\n\tsize mismatch for module_list.8.subnet1.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet1.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.8.subnet1.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet1.4.weight: copying a param with shape torch.Size([50, 512]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\n\tsize mismatch for module_list.8.subnet2.0.weight: copying a param with shape torch.Size([512, 25]) from checkpoint, the shape in current model is torch.Size([1024, 25]).\n\tsize mismatch for module_list.8.subnet2.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet2.2.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).\n\tsize mismatch for module_list.8.subnet2.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.8.subnet2.4.weight: copying a param with shape torch.Size([48, 512]) from checkpoint, the shape in current model is torch.Size([48, 1024])."
     ]
    }
   ],
   "source": [
    "version_folder = get_version_dir('results/patch_nr', 'custom_patch_nr', 1)\n",
    "loaded_model = PatchFlowModel(path=os.path.join(version_folder, 'custom_patch_nr_intermediate.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:08:51.368350Z",
     "end_time": "2023-10-19T00:08:51.386506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
