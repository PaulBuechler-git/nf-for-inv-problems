{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from flow_models import FlowModel\n",
    "from img_utils import ImageLoader, PatchExtractor\n",
    "from patch_nr_paper_model import create_NF\n",
    "from transforms import image_dequantization, image_normalization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T16:32:01.420398Z",
     "end_time": "2023-10-18T16:32:01.421813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T16:32:01.821492Z",
     "end_time": "2023-10-18T16:32:01.863077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-18T16:32:02.262959Z",
     "end_time": "2023-10-18T16:32:02.278296Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_flow_trainer(name: str, f_model: FlowModel, loss_fn, train_images: ImageLoader, validation_images: ImageLoader,\n",
    "                       patch_size=6, batch_size=64, steps=1000000, val_each_steps=1000, loss_log_each_step=100, device='cpu',\n",
    "                       quiet=False, lr=0.005):\n",
    "    if not quiet:\n",
    "        print(f'Started training for model {name}. \\n Will train {steps} steps in device={device}')\n",
    "\n",
    "    model = f_model.get_model()\n",
    "\n",
    "    patch_extractor = PatchExtractor(p_size=patch_size, device=device)\n",
    "    progress_bar = tqdm(range(steps)) if not quiet else range(steps)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f'Optimizer is initialized with this parameters: {optimizer.state_dict()}')\n",
    "\n",
    "    tmp_validation_loss = 0\n",
    "    tmp_loss =0\n",
    "\n",
    "    for step in progress_bar:\n",
    "        train_image = train_images.get_random_image()\n",
    "        train_patch_batch = patch_extractor.extract(train_image, batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        z, z_log_det = model(train_patch_batch, rev=True)\n",
    "        loss += loss_fn(z, z_log_det)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % loss_log_each_step == 0:\n",
    "            tmp_loss = loss\n",
    "            if not quiet:\n",
    "                progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "\n",
    "        if step % val_each_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                val_image = validation_images.get_random_image()\n",
    "                val_patch_batch = patch_extractor.extract(val_image, batch_size)\n",
    "                z_val, z_val_log_det = model(val_patch_batch, rev=True)\n",
    "                val_loss = loss_fn(z_val, z_val_log_det)\n",
    "                tmp_validation_loss = val_loss\n",
    "                if not quiet:\n",
    "                    progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "patch_size = 9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T16:32:03.048406Z",
     "end_time": "2023-10-18T16:32:03.056913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def log_likelihood_loss(z, z_log_det):\n",
    "    return torch.mean(0.5 * torch.sum(z**2, dim=1) - z_log_det)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T15:16:07.838257Z",
     "end_time": "2023-10-18T15:16:07.839709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = create_NF(num_layers=10, sub_net_size=512, dimension=patch_size**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T15:16:08.088468Z",
     "end_time": "2023-10-18T15:16:10.017563Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "deq_normalization = T.Compose([image_dequantization(device=DEVICE), image_normalization()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T15:16:10.063816Z",
     "end_time": "2023-10-18T15:16:10.094768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_images = ImageLoader('data/set12/train', transform=deq_normalization, device=DEVICE)\n",
    "validation_images = ImageLoader('data/set12/validate/05.png', transform=deq_normalization, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T15:16:45.516630Z",
     "end_time": "2023-10-18T15:16:45.567507Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for model set12_flow. \n",
      " Will train 1000000 steps in device=cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer is initialized with this parameters: {'state': {}, 'param_groups': [{'lr': 0.005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: -228.3835906982422, V:-214.90438842773438:   0%|          | 3977/1000000 [01:55<8:01:10, 34.50it/s]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpatch_flow_trainer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mset12_flow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_likelihood_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 27\u001B[0m, in \u001B[0;36mpatch_flow_trainer\u001B[0;34m(name, model, loss_fn, train_images, validation_images, patch_size, batch_size, steps, val_each_steps, loss_log_each_step, device, quiet, lr)\u001B[0m\n\u001B[1;32m     24\u001B[0m loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_fn(z, z_log_det)\n\u001B[1;32m     26\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 27\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m loss_log_each_step \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "patch_flow_trainer('set12_flow', model, log_likelihood_loss, train_images, validation_images, patch_size=patch_size, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
