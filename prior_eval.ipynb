{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dataset.FastPatchExtractor import FastPatchDataset, FastPatchExtractor\n",
    "from operators.noise_operator import NoiseOperator\n",
    "from patchNR.model import create_NF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:19.221131Z",
     "end_time": "2023-10-05T23:21:21.010205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:23.277393Z",
     "end_time": "2023-10-05T23:21:23.287554Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:24.216585Z",
     "end_time": "2023-10-05T23:21:26.776876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ReversibleGraphNet(\n  (module_list): ModuleList(\n    (0): GLOWCouplingBlock(\n      (subnet1): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n      (subnet2): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n    )\n    (1): PermuteRandom()\n    (2): GLOWCouplingBlock(\n      (subnet1): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n      (subnet2): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n    )\n    (3): PermuteRandom()\n    (4): GLOWCouplingBlock(\n      (subnet1): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n      (subnet2): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n    )\n    (5): PermuteRandom()\n    (6): GLOWCouplingBlock(\n      (subnet1): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n      (subnet2): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n    )\n    (7): PermuteRandom()\n    (8): GLOWCouplingBlock(\n      (subnet1): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n      (subnet2): Sequential(\n        (0): Linear(in_features=18, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=512, out_features=512, bias=True)\n        (3): ReLU()\n        (4): Linear(in_features=512, out_features=36, bias=True)\n      )\n    )\n    (9): PermuteRandom()\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size = 6\n",
    "num_layers = 5\n",
    "subnet_nodes = 512\n",
    "weight_path = 'patchNR/patchNR_weights/weights_material.pth'\n",
    "net = create_NF(num_layers, subnet_nodes, dimension=patch_size**2)\n",
    "weights = torch.load(weight_path, map_location=DEVICE)\n",
    "net.load_state_dict(weights['net_state_dict'])\n",
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_img_path = './data/material_pt_nr/train.png'\n",
    "known = FastPatchDataset(train_img_path, patch_size, device=DEVICE)\n",
    "test_img_path = './data/material_pt_nr/test.png'\n",
    "unknown = FastPatchDataset(test_img_path, patch_size, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:27.835296Z",
     "end_time": "2023-10-05T23:21:28.092762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_regularizer_val(batch):\n",
    "    pred_inv, log_det_inv = net(batch,rev=True)\n",
    "    reg = torch.mean(torch.sum(pred_inv**2,dim=1)/2) - torch.mean(log_det_inv)\n",
    "    return reg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:29.002543Z",
     "end_time": "2023-10-05T23:21:29.012576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size=40000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:29.889476Z",
     "end_time": "2023-10-05T23:21:29.897693Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known: -137.80453491210938, Unknown:  -134.50440979003906\n"
     ]
    }
   ],
   "source": [
    "known_batch = known.get_batch(batch_size)\n",
    "know_val = get_regularizer_val(known_batch.to(DEVICE))\n",
    "unknown_batch = unknown.get_batch(batch_size)\n",
    "unknown_val = get_regularizer_val(unknown_batch.to(DEVICE))\n",
    "print(f'Known: {know_val.item()}, Unknown:  {unknown_val.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:30.731691Z",
     "end_time": "2023-10-05T23:21:37.961906Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Expected behavior is that the regularizer value for the images differs whether the patch is corrupted or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "operator = NoiseOperator(mean=0, std=0.1, device=DEVICE)\n",
    "image = known.images[0]\n",
    "corrupted_image = operator(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:40.387307Z",
     "end_time": "2023-10-05T23:21:40.407110Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known: -135.8609619140625, Corrupted:  -135.73085021972656\n"
     ]
    }
   ],
   "source": [
    "patch_extractor = FastPatchExtractor(patch_size, device=DEVICE)\n",
    "batch = patch_extractor.extract(corrupted_image)[:batch_size]\n",
    "corrupted_val = get_regularizer_val(batch.to(DEVICE))\n",
    "known_batch_2 = known.patch_extractor.extract(known.images[0])[:batch_size]\n",
    "know_val_2 = get_regularizer_val(known_batch_2.to(DEVICE))\n",
    "print(f'Known: {know_val_2.item()}, Corrupted:  {corrupted_val.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:41.542616Z",
     "end_time": "2023-10-05T23:21:41.849228Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is satisfied"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(torch.reshape(known_batch_2[0].to('cpu'), (patch_size, patch_size)), cmap='gray')\n",
    "axes[0].set_title('Ground truth')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(torch.reshape(batch[0].to('cpu'), (patch_size, patch_size)), cmap='gray')\n",
    "axes[1].set_title('Noisy')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:21:48.120525Z",
     "end_time": "2023-10-05T23:21:48.366377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_reg_for_noise(patch_size, max_noise, step_size=1, device=DEVICE):\n",
    "    patch_extractor = FastPatchExtractor(patch_size, device=device)\n",
    "    x, y = [], []\n",
    "    for i in range(1, max_noise, step_size):\n",
    "        operator = NoiseOperator(mean=0, std=i, device=device)\n",
    "        image = known.images[0]\n",
    "        corrupted_image = operator(image)\n",
    "        batch = patch_extractor.extract(corrupted_image)[:batch_size]\n",
    "        corrupted_val = get_regularizer_val(batch.to(device))\n",
    "        x.append(i)\n",
    "        y.append(corrupted_val)\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:23:10.071377Z",
     "end_time": "2023-10-05T23:23:10.076006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.58 GiB total capacity; 13.47 GiB already allocated; 37.31 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m x,y \u001B[38;5;241m=\u001B[39m \u001B[43mget_reg_for_noise\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[15], line 8\u001B[0m, in \u001B[0;36mget_reg_for_noise\u001B[0;34m(patch_size, max_noise, step_size, device)\u001B[0m\n\u001B[1;32m      6\u001B[0m image \u001B[38;5;241m=\u001B[39m known\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      7\u001B[0m corrupted_image \u001B[38;5;241m=\u001B[39m operator(image)\n\u001B[0;32m----> 8\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[43mpatch_extractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorrupted_image\u001B[49m\u001B[43m)\u001B[49m[:batch_size]\n\u001B[1;32m      9\u001B[0m corrupted_val \u001B[38;5;241m=\u001B[39m get_regularizer_val(batch\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[1;32m     10\u001B[0m x\u001B[38;5;241m.\u001B[39mappend(i)\n",
      "File \u001B[0;32m~/nf-for-inv-problems/dataset/FastPatchExtractor.py:37\u001B[0m, in \u001B[0;36mFastPatchExtractor.extract\u001B[0;34m(self, image, batch_size)\u001B[0m\n\u001B[1;32m     35\u001B[0m     image \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((image, image[:, :, :\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_size, :]), \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     36\u001B[0m     image \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((image, image[:, :, :, :\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_size]), \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 37\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_size:\n\u001B[1;32m     40\u001B[0m     idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandperm(patches\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)[:batch_size]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/fold.py:298\u001B[0m, in \u001B[0;36mUnfold.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4697\u001B[0m, in \u001B[0;36munfold\u001B[0;34m(input, kernel_size, dilation, padding, stride)\u001B[0m\n\u001B[1;32m   4693\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m   4694\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m   4695\u001B[0m         unfold, (\u001B[38;5;28minput\u001B[39m,), \u001B[38;5;28minput\u001B[39m, kernel_size, dilation\u001B[38;5;241m=\u001B[39mdilation, padding\u001B[38;5;241m=\u001B[39mpadding, stride\u001B[38;5;241m=\u001B[39mstride\n\u001B[1;32m   4696\u001B[0m     )\n\u001B[0;32m-> 4697\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mim2col\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pair\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.58 GiB total capacity; 13.47 GiB already allocated; 37.31 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "x,y = get_reg_for_noise(patch_size, 150, step_size=1, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(39124992, 15653470208)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T23:24:29.829557Z",
     "end_time": "2023-10-05T23:24:29.871362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
