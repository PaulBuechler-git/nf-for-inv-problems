{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "from file_utils import create_versioned_dir, get_version_dir\n",
    "from flow_models import FlowModel\n",
    "from flow_models.PatchFlowModel import PatchFlowModel\n",
    "from img_utils import ImageLoader, PatchExtractor\n",
    "from transforms import image_dequantization, image_normalization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:30:52.622903Z",
     "end_time": "2023-10-19T00:30:54.511132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:30:54.523723Z",
     "end_time": "2023-10-19T00:30:54.529610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:30:54.537752Z",
     "end_time": "2023-10-19T00:30:54.567454Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_flow_trainer(name: str, path: str, model: FlowModel, loss_fn, train_images: ImageLoader, validation_images: ImageLoader,\n",
    "                       patch_size=6, batch_size=64, steps=750000, val_each_steps=1000, loss_log_each_step=100, device='cpu',\n",
    "                       quiet=False, lr=0.005):\n",
    "    if not quiet:\n",
    "        print(f'Started training for model {name}. \\n Will train {steps} steps in device={device}')\n",
    "    dir = create_versioned_dir(path, name)\n",
    "    if not quiet:\n",
    "        print(f'The weights, loss and the parameters will be stored at this location: {dir}')\n",
    "    hparams = model.get_hparams()\n",
    "    hparams['patch_size'] = patch_size\n",
    "    hparams['batch_size'] = patch_size\n",
    "    hparams['device'] = str(device)\n",
    "    hparams['train_img_path'] = train_images.path\n",
    "    hparams['validation_img_path'] = validation_images.path\n",
    "    hparams['model_name'] = name\n",
    "    hparams['lr'] = lr\n",
    "    json.dump(hparams, open(os.path.join(dir, 'hparams.yaml'), 'w'))\n",
    "\n",
    "\n",
    "    # create sqllite3 conection to save the loss values\n",
    "    connection = sqlite3.connect(os.path.join(dir, 'loss.db'))\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"CREATE TABLE flow_model_train_loss(step, loss)\")\n",
    "    cursor.execute(\"CREATE TABLE flow_model_validation_loss(step, loss)\")\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    patch_extractor = PatchExtractor(p_size=patch_size, device=device)\n",
    "    progress_bar = tqdm(range(steps)) if not quiet else range(steps)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f'Optimizer is initialized with this parameters: {optimizer.state_dict()}')\n",
    "\n",
    "    tmp_validation_loss = 0\n",
    "    tmp_loss =0\n",
    "\n",
    "    loss_buffer = []\n",
    "\n",
    "    for step in progress_bar:\n",
    "        train_image = train_images.get_random_image()\n",
    "        train_patch_batch = patch_extractor.extract(train_image, batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        z, z_log_det = model(train_patch_batch, rev=True)\n",
    "        loss += loss_fn(z, z_log_det)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % loss_log_each_step == 0:\n",
    "            tmp_loss = loss.item()\n",
    "            if not quiet:\n",
    "                progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "            loss_buffer.append((step, loss.item()))\n",
    "\n",
    "        if step % val_each_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                val_image = validation_images.get_random_image()\n",
    "                val_patch_batch = patch_extractor.extract(val_image, batch_size)\n",
    "                z_val, z_val_log_det = model(val_patch_batch, rev=True)\n",
    "                val_loss = loss_fn(z_val, z_val_log_det)\n",
    "                tmp_validation_loss = val_loss.item()\n",
    "                # write train loss buffer and validation loss to db\n",
    "                cursor.execute(\"INSERT INTO flow_model_validation_loss VALUES(?, ?)\", (step, val_loss.item()))\n",
    "                cursor.executemany(\"INSERT INTO flow_model_train_loss VALUES(?, ?)\", loss_buffer)\n",
    "                connection.commit()\n",
    "                # save checkpoint\n",
    "                torch.save(optimizer.state_dict(), os.path.join(dir, f'optimizer_dict.pth'))\n",
    "                torch.save(model.get_state(), os.path.join(dir, f'{name}_intermediate.pth'))\n",
    "                if not quiet:\n",
    "                    progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "    connection.close()\n",
    "    torch.save(model.get_state(), os.path.join(dir, f'{name}_final.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "patch_size = 7"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:34:01.088718Z",
     "end_time": "2023-10-19T00:34:01.130317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def log_likelihood_loss(z, z_log_det):\n",
    "    return torch.mean(0.5 * torch.sum(z**2, dim=1) - z_log_det)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:34:01.473369Z",
     "end_time": "2023-10-19T00:34:01.516284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model = PatchFlowModel(hparams={\"num_layers\": 5, \"sub_net_size\": 512, \"dimension\": patch_size ** 2}) #create_NF(num_layers=10, sub_net_size=512, dimension=patch_size**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:34:02.278586Z",
     "end_time": "2023-10-19T00:34:02.336442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "deq_normalization = T.Compose([\n",
    "    image_dequantization(device=DEVICE),\n",
    "    image_normalization()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:34:02.961180Z",
     "end_time": "2023-10-19T00:34:02.973212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_images = ImageLoader('data/material_pt_nr/train.png', transform=deq_normalization, device=DEVICE)\n",
    "validation_images = ImageLoader('data/material_pt_nr/validate.png', transform=deq_normalization, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:34:03.649138Z",
     "end_time": "2023-10-19T00:34:03.698344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for model custom_patch_nr. \n",
      " Will train 3000 steps in device=cuda\n",
      "The weights, loss and the parameters will be stored at this location: results/patch_nr/custom_patch_nr/version_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 5.787879943847656, V:24427.90625:   0%|          | 2/3000 [00:00<02:46, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer is initialized with this parameters: {'state': {}, 'param_groups': [{'lr': 0.005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: -117.49014282226562, V:24427.90625:   9%|â–‰         | 269/3000 [00:03<00:40, 67.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpatch_flow_trainer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom_patch_nr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresults/patch_nr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_likelihood_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 53\u001B[0m, in \u001B[0;36mpatch_flow_trainer\u001B[0;34m(name, path, model, loss_fn, train_images, validation_images, patch_size, batch_size, steps, val_each_steps, loss_log_each_step, device, quiet, lr)\u001B[0m\n\u001B[1;32m     50\u001B[0m loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_fn(z, z_log_det)\n\u001B[1;32m     52\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 53\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m loss_log_each_step \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "patch_flow_trainer('custom_patch_nr', 'results/patch_nr', model, log_likelihood_loss, train_images, validation_images, steps=3000, patch_size=patch_size, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:30:57.190713Z",
     "end_time": "2023-10-19T00:31:42.398420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PatchFlowModel._create_model() got an unexpected keyword argument 'patch_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m version_folder \u001B[38;5;241m=\u001B[39m get_version_dir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults/patch_nr\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_patch_nr\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m \u001B[43mPatchFlowModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mversion_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom_patch_nr_final.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nf-for-inv-problems/flow_models/PatchFlowModel.py:10\u001B[0m, in \u001B[0;36mPatchFlowModel.__init__\u001B[0;34m(self, hparams, path, device)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, hparams\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_layers\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msub_net_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1024\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdimension\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m7\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m}, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nf-for-inv-problems/flow_models/FlowModel.py:20\u001B[0m, in \u001B[0;36mFlowModel.__init__\u001B[0;34m(self, hparams, path, device)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     19\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo hyperparameters for model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m created_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m created_model\u001B[38;5;241m.\u001B[39mload_state_dict(model_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnet_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m created_model\n",
      "\u001B[0;31mTypeError\u001B[0m: PatchFlowModel._create_model() got an unexpected keyword argument 'patch_size'"
     ]
    }
   ],
   "source": [
    "version_folder = get_version_dir('results/patch_nr', 'custom_patch_nr', 5)\n",
    "loaded_model = PatchFlowModel(path=os.path.join(version_folder, 'custom_patch_nr_final.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-19T00:08:51.368350Z",
     "end_time": "2023-10-19T00:08:51.386506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
