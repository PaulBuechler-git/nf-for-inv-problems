{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from file_utils import create_versioned_dir\n",
    "from flow_models import FlowModel\n",
    "from flow_models.PatchFlowModel import PatchFlowModel\n",
    "from img_utils import ImageLoader, PatchExtractor\n",
    "from transforms import image_dequantization, image_normalization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:37.990785Z",
     "end_time": "2023-10-18T23:22:38.036412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:38.286359Z",
     "end_time": "2023-10-18T23:22:38.294684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:38.667949Z",
     "end_time": "2023-10-18T23:22:38.711788Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_flow_trainer(name: str, path: str, model: FlowModel, loss_fn, train_images: ImageLoader, validation_images: ImageLoader,\n",
    "                       patch_size=6, batch_size=64, steps=750000, val_each_steps=1000, loss_log_each_step=100, device='cpu',\n",
    "                       quiet=False, lr=0.005):\n",
    "\n",
    "    dir = create_versioned_dir(path, name)\n",
    "\n",
    "    model_hparams = model.get_hparams()\n",
    "    torch.save(model_hparams, os.path.join(dir, 'hparams.yaml'))\n",
    "\n",
    "    if not quiet:\n",
    "        print(f'Started training for model {name}. \\n Will train {steps} steps in device={device}')\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    patch_extractor = PatchExtractor(p_size=patch_size, device=device)\n",
    "    progress_bar = tqdm(range(steps)) if not quiet else range(steps)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f'Optimizer is initialized with this parameters: {optimizer.state_dict()}')\n",
    "\n",
    "    tmp_validation_loss = 0\n",
    "    tmp_loss =0\n",
    "\n",
    "    for step in progress_bar:\n",
    "        train_image = train_images.get_random_image()\n",
    "        train_patch_batch = patch_extractor.extract(train_image, batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        z, z_log_det = model(train_patch_batch, rev=True)\n",
    "        loss += loss_fn(z, z_log_det)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % loss_log_each_step == 0:\n",
    "            tmp_loss = loss\n",
    "            if not quiet:\n",
    "                progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')\n",
    "\n",
    "        if step % val_each_steps == 0:\n",
    "            with torch.no_grad():\n",
    "                val_image = validation_images.get_random_image()\n",
    "                val_patch_batch = patch_extractor.extract(val_image, batch_size)\n",
    "                z_val, z_val_log_det = model(val_patch_batch, rev=True)\n",
    "                val_loss = loss_fn(z_val, z_val_log_det)\n",
    "                tmp_validation_loss = val_loss\n",
    "                if not quiet:\n",
    "                    progress_bar.set_description_str(f'T: {tmp_loss}, V:{tmp_validation_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "patch_size = 7"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:39.041870Z",
     "end_time": "2023-10-18T23:22:39.043877Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def log_likelihood_loss(z, z_log_det):\n",
    "    return torch.mean(0.5 * torch.sum(z**2, dim=1) - z_log_det)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:39.543654Z",
     "end_time": "2023-10-18T23:22:39.555979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = PatchFlowModel(hparams={\"num_layers\": 5, \"sub_net_size\": 512, \"dimension\": patch_size ** 2}) #create_NF(num_layers=10, sub_net_size=512, dimension=patch_size**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:39.894596Z",
     "end_time": "2023-10-18T23:22:39.940088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "deq_normalization = T.Compose([\n",
    "    image_dequantization(device=DEVICE),\n",
    "    image_normalization()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:40.251960Z",
     "end_time": "2023-10-18T23:22:40.295708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_images = ImageLoader('data/material_pt_nr/train.png', transform=deq_normalization, device=DEVICE)\n",
    "validation_images = ImageLoader('data/material_pt_nr/validate.png', transform=deq_normalization, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-18T23:22:40.671105Z",
     "end_time": "2023-10-18T23:22:40.700833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/patch_nr/custom_patch_nr\n",
      "[]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PatchFlowModel' object has no attribute 'get_hparams'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpatch_flow_trainer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcustom_patch_nr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresults/patch_nr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_likelihood_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m750000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 7\u001B[0m, in \u001B[0;36mpatch_flow_trainer\u001B[0;34m(name, path, model, loss_fn, train_images, validation_images, patch_size, batch_size, steps, val_each_steps, loss_log_each_step, device, quiet, lr)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpatch_flow_trainer\u001B[39m(name: \u001B[38;5;28mstr\u001B[39m, path: \u001B[38;5;28mstr\u001B[39m, model: FlowModel, loss_fn, train_images: ImageLoader, validation_images: ImageLoader,\n\u001B[1;32m      2\u001B[0m                        patch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m750000\u001B[39m, val_each_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, loss_log_each_step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      3\u001B[0m                        quiet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mdir\u001B[39m \u001B[38;5;241m=\u001B[39m create_versioned_dir(path, name)\n\u001B[0;32m----> 7\u001B[0m     model_hparams \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_hparams\u001B[49m()\n\u001B[1;32m      8\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(model_hparams, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mdir\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhparams.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m quiet:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'PatchFlowModel' object has no attribute 'get_hparams'"
     ]
    }
   ],
   "source": [
    "patch_flow_trainer('custom_patch_nr', 'results/patch_nr', model, log_likelihood_loss, train_images, validation_images, steps=750000, patch_size=patch_size, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
